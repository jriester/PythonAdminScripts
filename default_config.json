{
  "InputFolders": {
    "_comment": "The directory that hosts the directories that contains the directories of logs too parse. Then you define the specific log directory that contains all logs for the specific issue you are trying to analyze",
    "Default_Folder_Path": "/Path/To/Directory/for/Parsing/Directories",
    "Input_Folder_Name": ""
  },
  "OutputFolders": {
    "_comment": "The following names are folders that are automatically created, these are where files are stored during processing.",
    "Folder_Name_For_Storing_Parsed_Logs": "Logs",
    "Folder_Name_For_Storing_Archives": "Archive_of_Compressed_Files",
    "Folder_Name_For_Tool_Output": "Processing_Results"
  },
  "LoggingConfigs": {
    "_comment": "This section defines the timestamp format for logging evets from this tool and the prefix strings for the output files from this tool.",
    "LogLevel": "INFO",
    "Output_Timestamp_Format": "%m_%d_%Y-%H_%M_%S",
    "Full_Output_Log_Name_Prefix": "Python-Regex-Searching-Log-File",
    "Individual_Search_Results_Prefix": "Parsed-Results",
    "Resultant_Patterns_In_Logs_Prefix": "Patterns-in-Results"
  },
  "RegexPatterns": {
    "_comment": "This is the list of patterns that are used to identify important log segments for review",
    "Remove_Times_For_Error_Or_Fatal": ".*\\d{4}-\\d{2}-\\d{1,2} \\d{1,2}:\\d{2}:\\d{2},\\d{3}.( ERROR | FATAL ).*|(org.apache.kafka.common.errors.*)",
    "Pattern_To_Find_Warns": ".*(WARN.*)",
    "Client_IDs": "(.*client.id.=.(.*))",
    "Start_Of_Configs": "^.*(Config values:.).*\\(.*",
    "Application_IDs": "(.*application.id.=.(.*))",
    "Replica_Fetcher_Errors": "(ReplicaFetcher.*Error sending fetch request.*)",
    "Broker_Disconnects": ".*(brokerId=\\d+.*Connection with.*disconnected.*)",
    "Failed_Connections": ".*java.io.IOException.*(Connection to (.*) failed.*)"
  },
  "SedPatterns": {
    "_comment": "This section defines the replacements performed to generalize the logs so that patterns can be extracted. The format should always be the pattern to find, then what to replace it with. All replacements are global",
    "Timestamps": {
      "Search": "[0-9]{4}-[0-9]{2}-[0-9]{2} [0-9]{2}:[0-9]{2}:[0-9]{2},[0-9]{3}",
      "Replace": "TIMESTAMP"
    },
    "Generalize_Number_sequences": {
      "Search": "((record\\(s\\) for _.{1,55}-[0-9]{1,5}:|Expiring|blocked for| Negative message latency|at offset|correlation id|timed out at|deadlineMs|nextAllowedTryMs|partition|offset|changelog-|generationId=)(|=| |=-))([0-9]{1,13})",
      "Replace": "\\1#########"
    },
    "Generalize_Task_IDs": {
      "Search": "(task(s?))( | ID .| .?|Id=)[0-9]{1,5}_[0-9]{1,5}.?",
      "Replace": "\\1 ID #########"
    },
    "Generalize_Attempts_Left": {
      "Search": "[0-9]{1,13} attempts left",
      "Replace": "\\1 ID #########"
    },
    "Generalize_Partition_Topic_Errors": {
      "Search": "(partition )(.*)(-[0-9]{1,4})",
      "Replace": "\\1  TOPIC_NAME"
    },
    "Generalize_UUID_Client_Names": {
      "Search": "(client.?[I|i]d.*-)([0-9]{1,6})",
      "Replace": "\\1UUID"
    },
    "Generalize_CSAS_IDs": {
      "Search": "(_C.AS_\\S*)_[0-9]{1,3}",
      "Replace": "\\1_UUID"
    },
    "KSQL_KSTREAMS_UUID_Removal": {
      "Search": "(vert.x-eventloop-thread|took)(.*)(,main|ms)",
      "Replace": "\\1_UUID"
    },
    "KSQL_KSTREAMS_ThreadID_Removal": {
      "Search": ".{8}-.{4}-.{4}-.{4}-.{12}(-StreamThread)?(-.{1,2})?",
      "Replace": "THREAD_UUID\\1"
    }

  }
}